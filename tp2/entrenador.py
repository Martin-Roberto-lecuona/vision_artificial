from sklearn import tree
from joblib import dump, load

# dataset
"""
EJEMPLO PROFESOR
X = [
    [6.53608067e-04, 6.07480284e-16, 9.67218398e-18, 1.40311655e-19, -1.18450102e-37, 8.60883492e-28, -1.12639633e-37],
    [6.07480284e-16, 9.67218398e-18, 1.40311655e-19, -1.18450102e-37, 8.60883492e-28, -1.12639633e-37, 6.53608067e-04],
    [6.53608067e-04, 6.07480284e-16, 9.67218398e-18, 1.40311655e-19, -1.18450102e-37, 8.60883492e-28, -1.12639633e-37],
    [1.40311655e-19, -1.18450102e-37, 8.60883492e-28, -1.12639633e-37, 6.53608067e-04, 6.07480284e-16, 9.67218398e-18],
    [8.60883492e-28, -1.12639633e-37, 6.53608067e-04, 6.07480284e-16, 9.67218398e-18, 1.40311655e-19, -1.18450102e-37],
    [6.53608067e-04, 6.07480284e-16, 9.67218398e-18, 1.40311655e-19, -1.18450102e-37, 8.60883492e-28, -1.12639633e-37],
    [9.67218398e-18, 1.40311655e-19, -1.18450102e-37, 8.60883492e-28, -1.12639633e-37, 6.53608067e-04, 6.07480284e-16],
]

# etiquetas, correspondientes a las muestras
Y = [1, 1, 1, 2, 2, 3, 3]
"""

X = [[0.19788617409772433, 0.0026044638058903805, 0.004532029966396208, 0.00010163817589955589, 2.4317424525569314e-08, 1.7172280533438054e-06, 6.455299603431292e-08], [0.19769169337448894, 0.0024443599603164614, 0.004552135429155137, 9.206815166143673e-05, 5.69498460318098e-09, 3.0483917031538597e-07, 5.9330799105716405e-08], [0.19763999817047773, 0.0023063797726652468, 0.004590679967967171, 8.33857186194314e-05, -1.3305653498441238e-08, -1.1103955055954986e-06, 4.9845925812951817e-08], [0.16513797576072986, 8.001619923956235e-05, 8.164113130159226e-06, 6.814396673786399e-08, 2.4814503503295492e-14, 3.120051514168012e-10, 4.4358065597186563e-14], [0.16521556414249325, 0.00010665358129920365, 7.3816336721387e-06, 4.971862207268096e-08, 1.853417762059087e-14, 1.6540221017433701e-10, 2.3742330406604664e-14], [0.1651965766875662, 9.066528950161882e-05, 7.091058948314823e-06, 4.437331996574594e-08, 1.5511949488123627e-14, 1.094171029618488e-10, 1.946612809167371e-14], [0.16515975062322275, 8.012759817175911e-05, 7.883177709944137e-06, 2.2133246343414953e-08, -8.083020803904465e-15, 1.9370694631095333e-10, 4.487682542686126e-15], [0.16514164830835934, 9.097825448456417e-05, 7.117796673400799e-06, 3.221438800209944e-08, -3.596546414078425e-16, 1.7913986701719907e-10, 1.5421603902349263e-14], [0.16218893947798715, 0.0009104181573081757, 1.0895952533997646e-05, 9.803615814524972e-08, -1.3055836332055415e-14, -8.244956376632985e-10, -1.0047927130297943e-13], [0.16205936753039257, 0.0008634184295859515, 1.2162317000471022e-05, 1.0572448174951553e-07, -1.443918929784931e-14, -8.409408613673489e-10, -1.190141327698784e-13], [0.16237655657986072, 0.0009682739376943127, 1.1533622270343006e-05, 1.1033807964482349e-07, -1.656248990692949e-14, -9.952371151768324e-10, -1.2336496509994623e-13], [0.16174794783135166, 0.0007620368702226385, 1.2282370938082847e-05, 9.84782188942048e-08, -2.0305204355882974e-15, -4.5614688787857075e-10, -1.082866813537134e-13]]
Y = [1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3]
# entrenamiento
clasificador = tree.DecisionTreeClassifier().fit(X, Y)

# visualización del árbol de decisión resultante
tree.plot_tree(clasificador)

# guarda el modelo en un archivo
dump(clasificador, 'filename.joblib')

# en otro programa, se puede cargar el modelo guardado
clasificadorRecuperado = load('filename.joblib')
